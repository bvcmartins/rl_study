{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import cv2\n",
    "import time\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ale_py\n",
    "gym.register_envs(ale_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDQN_CNN1(nn.Module):\n",
    "    \"\"\"Original CNN architecture (32->64->64 filters)\"\"\"\n",
    "    def __init__(self, input_channels, action_size):\n",
    "        super(ConvDQN_CNN1, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=8, stride=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.feature_size = self._get_conv_output_size()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.feature_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, action_size)\n",
    "        )\n",
    "    \n",
    "    def _get_conv_output_size(self):\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 2, 84, 84)\n",
    "            conv_output = self.conv(dummy_input)\n",
    "            return conv_output.numel() // conv_output.size(0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class ConvDQN_CNN2(nn.Module):\n",
    "    \"\"\"Optimized CNN architecture (32->36->20 filters)\"\"\"\n",
    "    def __init__(self, input_channels, action_size):\n",
    "        super(ConvDQN_CNN2, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=8, stride=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 36, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(36, 20, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.feature_size = self._get_conv_output_size()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.feature_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, action_size)\n",
    "        )\n",
    "    \n",
    "    def _get_conv_output_size(self):\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 2, 84, 84)\n",
    "            conv_output = self.conv(dummy_input)\n",
    "            return conv_output.numel() // conv_output.size(0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    gray = np.mean(frame, axis=2).astype(np.uint8)\n",
    "    cropped = gray[34:194, :]\n",
    "    resized = cv2.resize(cropped, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "    return resized.astype(np.float32) / 255.0\n",
    "\n",
    "class FrameStack:\n",
    "    def __init__(self, num_frames=2):\n",
    "        self.num_frames = num_frames\n",
    "        self.frames = deque(maxlen=num_frames)\n",
    "    \n",
    "    def reset(self, frame):\n",
    "        processed_frame = preprocess_frame(frame)\n",
    "        for _ in range(self.num_frames):\n",
    "            self.frames.append(processed_frame)\n",
    "        return self.get_stacked()\n",
    "    \n",
    "    def step(self, frame):\n",
    "        processed_frame = preprocess_frame(frame)\n",
    "        self.frames.append(processed_frame)\n",
    "        return self.get_stacked()\n",
    "    \n",
    "    def get_stacked(self):\n",
    "        return np.stack(list(self.frames), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_run_checkpoints():\n",
    "    \"\"\"Find checkpoints from the most recent training run\"\"\"\n",
    "    artifacts_dir = Path.home() / \"dev\" / \"rl_study\" / \"artifacts\"\n",
    "    \n",
    "    run_dirs = [d for d in artifacts_dir.glob(\"run_*\") if d.is_dir()]\n",
    "    \n",
    "    if not run_dirs:\n",
    "        return []\n",
    "    \n",
    "    latest_run_dir = max(run_dirs, key=lambda d: d.stat().st_mtime)\n",
    "    print(f\"Latest run: {latest_run_dir.name}\")\n",
    "    \n",
    "    checkpoint_files = list(latest_run_dir.glob(\"*checkpoint*.pth\"))\n",
    "    \n",
    "    checkpoints = []\n",
    "    for file_path in checkpoint_files:\n",
    "        checkpoints.append({\n",
    "            'path': str(file_path),\n",
    "            'filename': file_path.name,\n",
    "            'run_dir': latest_run_dir.name\n",
    "        })\n",
    "    \n",
    "    # Sort checkpoints by episode number extracted from filename\n",
    "    def extract_episode_number(checkpoint):\n",
    "        # Extract episode number from filename like \"pong_dqn_cnn_v2_checkpoint_ep1000.pth\"\n",
    "        filename = checkpoint['filename']\n",
    "        try:\n",
    "            # Find the episode number after \"ep\"\n",
    "            ep_start = filename.find('ep') + 2\n",
    "            ep_end = filename.find('.pth')\n",
    "            episode_num = int(filename[ep_start:ep_end])\n",
    "            return episode_num\n",
    "        except (ValueError, AttributeError):\n",
    "            return 0  # Default for files without episode numbers\n",
    "    \n",
    "    # Sort by episode number\n",
    "    checkpoints.sort(key=extract_episode_number)\n",
    "    \n",
    "    return checkpoints\n",
    "\n",
    "def load_model(checkpoint_path, cnn_type=\"cnn1\"):\n",
    "    \"\"\"Load model from checkpoint with specified CNN architecture\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to checkpoint file\n",
    "        cnn_type: Either 'cnn1' for original architecture or 'cnn2' for optimized architecture\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    # Select model architecture based on cnn_type\n",
    "    if cnn_type.lower() == \"cnn1\":\n",
    "        model = ConvDQN_CNN1(input_channels=2, action_size=6).to(device)\n",
    "        arch_name = \"CNN1 (32→64→64)\"\n",
    "    elif cnn_type.lower() == \"cnn2\":\n",
    "        model = ConvDQN_CNN2(input_channels=2, action_size=6).to(device)\n",
    "        arch_name = \"CNN2 (32→36→20)\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown CNN type: {cnn_type}. Use 'cnn1' or 'cnn2'\")\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    metadata = {\n",
    "        'episode': checkpoint.get('episode', 'unknown'),\n",
    "        'avg_reward': checkpoint.get('avg_reward', 'unknown'),\n",
    "        'epsilon': checkpoint.get('epsilon', 'unknown'),\n",
    "        'architecture': arch_name\n",
    "    }\n",
    "    \n",
    "    return model, metadata, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_game_frame(raw_frame, processed_frame, stacked_frames, q_values, action, reward, step, total_reward, checkpoint_name, architecture):\n",
    "    \"\"\"Show the current game state and agent decision\"\"\"\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    fig.suptitle(f'{checkpoint_name} ({architecture}) - Step {step} - Action: {action}, Step Reward: {reward:.1f}, Total: {total_reward:.1f}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Raw game frame\n",
    "    axes[0].imshow(raw_frame)\n",
    "    axes[0].set_title('Raw Game Frame')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Processed frame that agent sees\n",
    "    axes[1].imshow(processed_frame, cmap='gray')\n",
    "    axes[1].set_title('Processed Frame (84x84)')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Q-values\n",
    "    actions = ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n",
    "    colors = ['red' if i == action else 'blue' for i in range(len(q_values))]\n",
    "    bars = axes[2].bar(range(len(q_values)), q_values, color=colors, alpha=0.7)\n",
    "    axes[2].set_title('Q-Values (Selected Action in Red)')\n",
    "    axes[2].set_xlabel('Actions')\n",
    "    axes[2].set_ylabel('Q-Value')\n",
    "    axes[2].set_xticks(range(len(actions)))\n",
    "    axes[2].set_xticklabels(actions, rotation=45)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, val) in enumerate(zip(bars, q_values)):\n",
    "        axes[2].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                        f'{val:.2f}', ha='center', va='bottom', \n",
    "                        fontweight='bold' if i == action else 'normal')\n",
    "    \n",
    "    # Frame difference (movement detection)\n",
    "    frame_diff = np.abs(stacked_frames[1] - stacked_frames[0])\n",
    "    axes[3].imshow(frame_diff, cmap='hot')\n",
    "    axes[3].set_title('Movement Detection')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def play_and_visualize_game(model, device, checkpoint_name, architecture):\n    \"\"\"Play one complete game and show every 10th step\"\"\"\n    env = gym.make('PongNoFrameskip-v4')\n    \n    print(f\"Playing game with {checkpoint_name} using {architecture}\")\n    print(\"Showing every 10th step of the game\")\n    print(\"=\" * 60)\n    \n    state, _ = env.reset()\n    frame_stack = FrameStack(2)\n    stacked_state = frame_stack.reset(state)\n    \n    total_reward = 0\n    step_count = 0\n    done = False\n    \n    while not done:\n        # Get action from model\n        with torch.no_grad():\n            state_tensor = torch.FloatTensor(stacked_state).unsqueeze(0).to(device)\n            q_values = model(state_tensor)\n            action = q_values.max(1)[1].item()\n            q_vals_numpy = q_values.cpu().numpy()[0]\n        \n        # Execute action with frame skipping\n        step_reward = 0\n        for _ in range(4):  # Frame skip\n            next_state, reward, terminated, truncated, _ = env.step(action)\n            step_reward += reward\n            if terminated or truncated:\n                break\n        \n        done = terminated or truncated\n        total_reward += step_reward\n        \n        # Show visualization every 10 steps\n        if step_count % 10 == 0:\n            processed_current = preprocess_frame(next_state)\n            clear_output(wait=True)\n            visualize_game_frame(\n                raw_frame=next_state,\n                processed_frame=processed_current,\n                stacked_frames=stacked_state,\n                q_values=q_vals_numpy,\n                action=action,\n                reward=step_reward,\n                step=step_count,\n                total_reward=total_reward,\n                checkpoint_name=checkpoint_name,\n                architecture=architecture\n            )\n            \n            print(f\"Step {step_count}: Action={action}, Reward={step_reward:.1f}, Total={total_reward:.1f}\")\n            \n            # Small delay to make it watchable\n            time.sleep(0.2)\n        \n        # Update state\n        stacked_state = frame_stack.step(next_state)\n        step_count += 1\n    \n    env.close()\n    \n    print(f\"\\nGame finished!\")\n    print(f\"Final reward: {total_reward}\")\n    print(f\"Game length: {step_count} steps\")\n    print(\"=\" * 60)\n    \n    return total_reward, step_count"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest run: run_c2fe49760fe14990ad1b4a0df89b985b\n",
      "Found 39 checkpoints from latest run:\n",
      "0: pong_dqn_cnn_v2_checkpoint_ep1000.pth\n",
      "1: pong_dqn_cnn_v2_checkpoint_ep2000.pth\n",
      "2: pong_dqn_cnn_v2_checkpoint_ep3000.pth\n",
      "3: pong_dqn_cnn_v2_checkpoint_ep4000.pth\n",
      "4: pong_dqn_cnn_v2_checkpoint_ep5000.pth\n",
      "5: pong_dqn_cnn_v2_checkpoint_ep6000.pth\n",
      "6: pong_dqn_cnn_v2_checkpoint_ep7000.pth\n",
      "7: pong_dqn_cnn_v2_checkpoint_ep8000.pth\n",
      "8: pong_dqn_cnn_v2_checkpoint_ep9000.pth\n",
      "9: pong_dqn_cnn_v2_checkpoint_ep10000.pth\n",
      "10: pong_dqn_cnn_v2_checkpoint_ep11000.pth\n",
      "11: pong_dqn_cnn_v2_checkpoint_ep12000.pth\n",
      "12: pong_dqn_cnn_v2_checkpoint_ep13000.pth\n",
      "13: pong_dqn_cnn_v2_checkpoint_ep14000.pth\n",
      "14: pong_dqn_cnn_v2_checkpoint_ep15000.pth\n",
      "15: pong_dqn_cnn_v2_checkpoint_ep16000.pth\n",
      "16: pong_dqn_cnn_v2_checkpoint_ep17000.pth\n",
      "17: pong_dqn_cnn_v2_checkpoint_ep18000.pth\n",
      "18: pong_dqn_cnn_v2_checkpoint_ep19000.pth\n",
      "19: pong_dqn_cnn_v2_checkpoint_ep20000.pth\n",
      "20: pong_dqn_cnn_v2_checkpoint_ep21000.pth\n",
      "21: pong_dqn_cnn_v2_checkpoint_ep22000.pth\n",
      "22: pong_dqn_cnn_v2_checkpoint_ep23000.pth\n",
      "23: pong_dqn_cnn_v2_checkpoint_ep24000.pth\n",
      "24: pong_dqn_cnn_v2_checkpoint_ep25000.pth\n",
      "25: pong_dqn_cnn_v2_checkpoint_ep26000.pth\n",
      "26: pong_dqn_cnn_v2_checkpoint_ep27000.pth\n",
      "27: pong_dqn_cnn_v2_checkpoint_ep28000.pth\n",
      "28: pong_dqn_cnn_v2_checkpoint_ep29000.pth\n",
      "29: pong_dqn_cnn_v2_checkpoint_ep30000.pth\n",
      "30: pong_dqn_cnn_v2_checkpoint_ep31000.pth\n",
      "31: pong_dqn_cnn_v2_checkpoint_ep32000.pth\n",
      "32: pong_dqn_cnn_v2_checkpoint_ep33000.pth\n",
      "33: pong_dqn_cnn_v2_checkpoint_ep34000.pth\n",
      "34: pong_dqn_cnn_v2_checkpoint_ep35000.pth\n",
      "35: pong_dqn_cnn_v2_checkpoint_ep36000.pth\n",
      "36: pong_dqn_cnn_v2_checkpoint_ep37000.pth\n",
      "37: pong_dqn_cnn_v2_checkpoint_ep38000.pth\n",
      "38: pong_dqn_cnn_v2_checkpoint_ep39000.pth\n"
     ]
    }
   ],
   "source": [
    "# Find and display available checkpoints\n",
    "checkpoints = find_latest_run_checkpoints()\n",
    "\n",
    "if checkpoints:\n",
    "    print(f\"Found {len(checkpoints)} checkpoints from latest run:\")\n",
    "    for i, cp in enumerate(checkpoints):\n",
    "        print(f\"{i}: {cp['filename']}\")\n",
    "else:\n",
    "    print(\"No checkpoints found. Run training first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# CONFIGURATION: Select model architecture\n# Use \"cnn1\" for pong_dqn_cnn.ipynb (32->64->64 filters)\n# Use \"cnn2\" for pong_dqn_cnn_v2.ipynb (32->36->20 filters)\nARCH = \"cnn2\"  # Use \"cnn1\" for original (32->64->64) or \"cnn2\" for optimized (32->36->20)\n\n# Select which checkpoint to analyze (play one game per checkpoint)\nif checkpoints:\n    print(f\"Using model architecture: {ARCH.upper()}\")\n    print(\"Available checkpoints (now sorted by episode number):\")\n    for i, checkpoint in enumerate(checkpoints):\n        print(f\"{i}: {checkpoint['filename']}\")\n    \n    # You can modify this to select specific checkpoints or analyze all\n    # For detailed step-by-step analysis, let's analyze fewer checkpoints\n    selected_indices = list(range(0, len(checkpoints), 10))  # Every 10th checkpoint to avoid too many games\n    print(f\"\\nAnalyzing checkpoints (every 10th): {selected_indices}\")\n    print(\"=\" * 80)\n    \n    results = []\n    \n    for idx in selected_indices:\n        checkpoint = checkpoints[idx]\n        print(f\"\\n{'='*80}\")\n        print(f\"ANALYZING CHECKPOINT {idx}: {checkpoint['filename']}\")\n        print(f\"{'='*80}\")\n        \n        try:\n            # Load model with selected architecture\n            model, metadata, device = load_model(checkpoint['path'], cnn_type=ARCH)\n            print(f\"Training Episode: {metadata['episode']}\")\n            print(f\"Training Avg Reward: {metadata['avg_reward']}\")\n            print(f\"Training Epsilon: {metadata['epsilon']}\")\n            print(f\"Architecture: {metadata['architecture']}\")\n            print()\n            \n            # Play one complete game and visualize EVERY step\n            final_reward, game_length = play_and_visualize_game(\n                model, device, checkpoint['filename'], metadata['architecture']\n            )\n            \n            # Store results\n            results.append({\n                'checkpoint': checkpoint['filename'],\n                'training_episode': metadata['episode'],\n                'training_avg_reward': metadata['avg_reward'],\n                'game_reward': final_reward,\n                'game_length': game_length\n            })\n            \n        except Exception as e:\n            print(f\"Error with checkpoint {checkpoint['filename']}: {e}\")\n            continue\n    \n    # Summary of results\n    if results:\n        print(f\"\\n{'='*80}\")\n        print(\"ANALYSIS SUMMARY\")\n        print(f\"{'='*80}\")\n        for result in results:\n            print(f\"Checkpoint: {result['checkpoint']}\")\n            print(f\"  Training Ep: {result['training_episode']}, Training Avg: {result['training_avg_reward']}\")\n            print(f\"  Game Reward: {result['game_reward']}, Game Length: {result['game_length']}\")\n            print()\n            \nelse:\n    print(\"No checkpoints available to analyze!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}