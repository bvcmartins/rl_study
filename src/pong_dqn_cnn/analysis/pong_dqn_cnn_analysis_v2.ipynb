{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output, Video, display, HTML\n",
    "\n",
    "# Import visualization utilities\n",
    "from visualization_utils import (\n",
    "    preprocess_frame,\n",
    "    FrameStack,\n",
    "    visualize_game_frame,\n",
    "    play_and_visualize_game,\n",
    "    check_existing_videos,\n",
    "    display_video_grid,\n",
    "    extract_episode_or_step_number\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ale_py\n",
    "gym.register_envs(ale_py)\n",
    "\n",
    "# VISUALIZATION CONFIGURATION PARAMETERS\n",
    "VISUALIZATION_FRAME_SKIP = 10  # Show every Nth step (10 = show every 10th step)\n",
    "# VISUALIZATION_FRAME_SKIP = 5   # More frequent visualization\n",
    "# VISUALIZATION_FRAME_SKIP = 20  # Less frequent visualization\n",
    "# VISUALIZATION_FRAME_SKIP = 1   # Show every single step (warning: very slow!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDQN_CNN2(nn.Module):\n",
    "    \"\"\"V2 CNN architecture (32->36->20 filters)\"\"\"\n",
    "    def __init__(self, input_channels, action_size):\n",
    "        super(ConvDQN_CNN2, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=8, stride=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 36, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(36, 20, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.feature_size = self._get_conv_output_size()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.feature_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, action_size)\n",
    "        )\n",
    "    \n",
    "    def _get_conv_output_size(self):\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 2, 84, 84)\n",
    "            conv_output = self.conv(dummy_input)\n",
    "            return conv_output.numel() // conv_output.size(0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_v2_run_checkpoints():\n",
    "    \"\"\"Find checkpoints from the most recent v2 training run\"\"\"\n",
    "    # Point to specific v2 run directory\n",
    "    v2_run_dir = Path.home() / \"dev\" / \"rl_study\" / \"artifacts\" / \"run_19ced322175f4bcd886ed9089e5bff78\"\n",
    "    \n",
    "    if not v2_run_dir.exists():\n",
    "        print(f\"V2 run directory not found: {v2_run_dir}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Using v2 run: {v2_run_dir.name}\")\n",
    "    \n",
    "    checkpoint_files = list(v2_run_dir.glob(\"*checkpoint*.pth\"))\n",
    "    \n",
    "    checkpoints = []\n",
    "    for file_path in checkpoint_files:\n",
    "        checkpoints.append({\n",
    "            'path': str(file_path),\n",
    "            'filename': file_path.name,\n",
    "            'run_dir': v2_run_dir.name\n",
    "        })\n",
    "    \n",
    "    # Sort by episode/step number\n",
    "    checkpoints.sort(key=extract_episode_or_step_number)\n",
    "    \n",
    "    return checkpoints\n",
    "\n",
    "def load_model(checkpoint_path):\n",
    "    \"\"\"Load v2 model from checkpoint\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    # Create v2 model\n",
    "    model = ConvDQN_CNN2(input_channels=2, action_size=6).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Extract metadata\n",
    "    metadata = {\n",
    "        'episode': checkpoint.get('episode', checkpoint.get('total_steps', 'unknown')),\n",
    "        'avg_reward': checkpoint.get('avg_reward', 'unknown'),\n",
    "        'epsilon': checkpoint.get('epsilon', 'unknown'),\n",
    "        'architecture': 'V2 (32→36→20)',\n",
    "        'run_id': checkpoint.get('run_id', 'unknown'),\n",
    "        'total_steps': checkpoint.get('total_steps', 'unknown')\n",
    "    }\n",
    "    \n",
    "    return model, metadata, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using v2 run: run_19ced322175f4bcd886ed9089e5bff78\n",
      "Found 4 checkpoints from v2 run:\n",
      "0: pong_dqn_cnn_v2_checkpoint_ep0.pth\n",
      "1: pong_dqn_cnn_v2_checkpoint_ep10000.pth\n",
      "2: pong_dqn_cnn_v2_checkpoint_ep20000.pth\n",
      "3: pong_dqn_cnn_v2_checkpoint_ep30000.pth\n"
     ]
    }
   ],
   "source": [
    "# Find and display available v2 checkpoints\n",
    "checkpoints = find_v2_run_checkpoints()\n",
    "\n",
    "if checkpoints:\n",
    "    print(f\"Found {len(checkpoints)} checkpoints from v2 run:\")\n",
    "    for i, cp in enumerate(checkpoints):\n",
    "        print(f\"{i}: {cp['filename']}\")\n",
    "else:\n",
    "    print(\"No checkpoints found. Run v2 training first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FOUND 4 EXISTING GAMEPLAY VIDEOS\n",
      "================================================================================\n",
      "✓ pong_dqn_cnn_v2_checkpoint_ep0.pth: 0.70 MB\n",
      "  Path: /home/bmartins/dev/rl_study/artifacts/run_19ced322175f4bcd886ed9089e5bff78/pong_dqn_cnn_v2_checkpoint_ep0_gameplay.mp4\n",
      "✓ pong_dqn_cnn_v2_checkpoint_ep10000.pth: 0.80 MB\n",
      "  Path: /home/bmartins/dev/rl_study/artifacts/run_19ced322175f4bcd886ed9089e5bff78/pong_dqn_cnn_v2_checkpoint_ep10000_gameplay.mp4\n",
      "✓ pong_dqn_cnn_v2_checkpoint_ep20000.pth: 4.00 MB\n",
      "  Path: /home/bmartins/dev/rl_study/artifacts/run_19ced322175f4bcd886ed9089e5bff78/pong_dqn_cnn_v2_checkpoint_ep20000_gameplay.mp4\n",
      "✓ pong_dqn_cnn_v2_checkpoint_ep30000.pth: 1.64 MB\n",
      "  Path: /home/bmartins/dev/rl_study/artifacts/run_19ced322175f4bcd886ed9089e5bff78/pong_dqn_cnn_v2_checkpoint_ep30000_gameplay.mp4\n",
      "\n",
      "================================================================================\n",
      "DISPLAYING EXISTING VIDEOS\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; flex-wrap: wrap; gap: 20px;\">\n",
       "        <div style=\"flex: 1; min-width: 300px; max-width: 500px;\">\n",
       "            <h3>pong_dqn_cnn_v2_ep0</h3>\n",
       "            <video width=\"100%\" controls>\n",
       "                <source src=\"/home/bmartins/dev/rl_study/artifacts/run_19ced322175f4bcd886ed9089e5bff78/pong_dqn_cnn_v2_checkpoint_ep0_gameplay.mp4\" type=\"video/mp4\">\n",
       "                Your browser does not support the video tag.\n",
       "            </video>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"flex: 1; min-width: 300px; max-width: 500px;\">\n",
       "            <h3>pong_dqn_cnn_v2_ep10000</h3>\n",
       "            <video width=\"100%\" controls>\n",
       "                <source src=\"/home/bmartins/dev/rl_study/artifacts/run_19ced322175f4bcd886ed9089e5bff78/pong_dqn_cnn_v2_checkpoint_ep10000_gameplay.mp4\" type=\"video/mp4\">\n",
       "                Your browser does not support the video tag.\n",
       "            </video>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"flex: 1; min-width: 300px; max-width: 500px;\">\n",
       "            <h3>pong_dqn_cnn_v2_ep20000</h3>\n",
       "            <video width=\"100%\" controls>\n",
       "                <source src=\"/home/bmartins/dev/rl_study/artifacts/run_19ced322175f4bcd886ed9089e5bff78/pong_dqn_cnn_v2_checkpoint_ep20000_gameplay.mp4\" type=\"video/mp4\">\n",
       "                Your browser does not support the video tag.\n",
       "            </video>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"flex: 1; min-width: 300px; max-width: 500px;\">\n",
       "            <h3>pong_dqn_cnn_v2_ep30000</h3>\n",
       "            <video width=\"100%\" controls>\n",
       "                <source src=\"/home/bmartins/dev/rl_study/artifacts/run_19ced322175f4bcd886ed9089e5bff78/pong_dqn_cnn_v2_checkpoint_ep30000_gameplay.mp4\" type=\"video/mp4\">\n",
       "                Your browser does not support the video tag.\n",
       "            </video>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for existing videos and display them\n",
    "if checkpoints:\n",
    "    existing_videos = check_existing_videos(checkpoints)\n",
    "    \n",
    "    if existing_videos:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"FOUND {len(existing_videos)} EXISTING GAMEPLAY VIDEOS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for checkpoint_name, video_info in existing_videos.items():\n",
    "            print(f\"✓ {checkpoint_name}: {video_info['size_mb']:.2f} MB\")\n",
    "            print(f\"  Path: {video_info['path']}\")\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"DISPLAYING EXISTING VIDEOS\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        # Display all existing videos\n",
    "        video_paths = [str(v['path']) for v in existing_videos.values()]\n",
    "        titles = [name.replace('_checkpoint', '').replace('.pth', '') for name in existing_videos.keys()]\n",
    "        display_video_grid(video_paths, titles)\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nNo existing videos found. Videos will be generated in the next cell.\")\n",
    "else:\n",
    "    print(\"No checkpoints available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available checkpoints (sorted by episode/step number):\n",
      "0: pong_dqn_cnn_v2_checkpoint_ep0.pth\n",
      "1: pong_dqn_cnn_v2_checkpoint_ep10000.pth\n",
      "2: pong_dqn_cnn_v2_checkpoint_ep20000.pth\n",
      "3: pong_dqn_cnn_v2_checkpoint_ep30000.pth\n",
      "\n",
      "Analyzing all 4 checkpoints: [0, 1, 2, 3]\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANALYZING CHECKPOINT 0: pong_dqn_cnn_v2_checkpoint_ep0.pth\n",
      "================================================================================\n",
      "Architecture: V2 (32→36→20)\n",
      "Training Episode: 0\n",
      "Training Avg Reward: -19.0\n",
      "Training Epsilon: 0.995\n",
      "Run ID: 19ced322175f4bcd886ed9089e5bff78\n",
      "\n",
      "✓ Video already exists: /home/bmartins/dev/rl_study/artifacts/run_19ced322175f4bcd886ed9089e5bff78/pong_dqn_cnn_v2_checkpoint_ep0_gameplay.mp4\n",
      "  Skipping gameplay generation. Set FORCE_REGENERATE=True to regenerate.\n",
      "\n",
      "================================================================================\n",
      "ANALYZING CHECKPOINT 1: pong_dqn_cnn_v2_checkpoint_ep10000.pth\n",
      "================================================================================\n",
      "Architecture: V2 (32→36→20)\n",
      "Training Episode: 10000\n",
      "Training Avg Reward: -14.0\n",
      "Training Epsilon: 0.00998645168764533\n",
      "Run ID: 19ced322175f4bcd886ed9089e5bff78\n",
      "\n",
      "✓ Video already exists: /home/bmartins/dev/rl_study/artifacts/run_19ced322175f4bcd886ed9089e5bff78/pong_dqn_cnn_v2_checkpoint_ep10000_gameplay.mp4\n",
      "  Skipping gameplay generation. Set FORCE_REGENERATE=True to regenerate.\n",
      "\n",
      "================================================================================\n",
      "ANALYZING CHECKPOINT 2: pong_dqn_cnn_v2_checkpoint_ep20000.pth\n",
      "================================================================================\n",
      "Architecture: V2 (32→36→20)\n",
      "Training Episode: 20000\n",
      "Training Avg Reward: -3.9\n",
      "Training Epsilon: 0.00998645168764533\n",
      "Run ID: 19ced322175f4bcd886ed9089e5bff78\n",
      "\n",
      "✓ Video already exists: /home/bmartins/dev/rl_study/artifacts/run_19ced322175f4bcd886ed9089e5bff78/pong_dqn_cnn_v2_checkpoint_ep20000_gameplay.mp4\n",
      "  Skipping gameplay generation. Set FORCE_REGENERATE=True to regenerate.\n",
      "\n",
      "================================================================================\n",
      "ANALYZING CHECKPOINT 3: pong_dqn_cnn_v2_checkpoint_ep30000.pth\n",
      "================================================================================\n",
      "Architecture: V2 (32→36→20)\n",
      "Training Episode: 30000\n",
      "Training Avg Reward: 17.8\n",
      "Training Epsilon: 0.00998645168764533\n",
      "Run ID: 19ced322175f4bcd886ed9089e5bff78\n",
      "\n",
      "✓ Video already exists: /home/bmartins/dev/rl_study/artifacts/run_19ced322175f4bcd886ed9089e5bff78/pong_dqn_cnn_v2_checkpoint_ep30000_gameplay.mp4\n",
      "  Skipping gameplay generation. Set FORCE_REGENERATE=True to regenerate.\n",
      "\n",
      "====================================================================================================\n",
      "COMPREHENSIVE ANALYSIS SUMMARY - V2 RUN\n",
      "====================================================================================================\n",
      "\n",
      "Checkpoints with existing videos (4):\n",
      "Checkpoint                               Architecture         Train Ep   Video Size (MB)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "pong_dqn_cnn_v2_checkpoint_ep0.pth       V2 (32→36→20)        0          0.70           \n",
      "pong_dqn_cnn_v2_checkpoint_ep10000.pth   V2 (32→36→20)        10000      0.80           \n",
      "pong_dqn_cnn_v2_checkpoint_ep20000.pth   V2 (32→36→20)        20000      4.00           \n",
      "pong_dqn_cnn_v2_checkpoint_ep30000.pth   V2 (32→36→20)        30000      1.64           \n",
      "\n",
      "Videos location: /home/bmartins/dev/rl_study/artifacts/run_19ced322175f4bcd886ed9089e5bff78\n",
      "  Existing videos reused: 4\n"
     ]
    }
   ],
   "source": [
    "# Video saving configuration\n",
    "SAVE_VIDEOS = True  # Set to True to save gameplay videos\n",
    "FORCE_REGENERATE = False  # Set to True to regenerate videos even if they exist\n",
    "\n",
    "# Select which checkpoint to analyze\n",
    "if checkpoints:\n",
    "    print(\"Available checkpoints (sorted by episode/step number):\")\n",
    "    for i, checkpoint in enumerate(checkpoints):\n",
    "        print(f\"{i}: {checkpoint['filename']}\")\n",
    "    \n",
    "    # Select checkpoints to analyze\n",
    "    if len(checkpoints) > 10:\n",
    "        selected_indices = list(range(0, len(checkpoints), max(1, len(checkpoints) // 10)))\n",
    "        print(f\"\\nAnalyzing {len(selected_indices)} checkpoints (evenly distributed): {selected_indices}\")\n",
    "    else:\n",
    "        selected_indices = list(range(len(checkpoints)))\n",
    "        print(f\"\\nAnalyzing all {len(selected_indices)} checkpoints: {selected_indices}\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    results = []\n",
    "    artifacts_dir = Path(checkpoints[0]['path']).parent\n",
    "    existing_videos = check_existing_videos(checkpoints)\n",
    "    \n",
    "    for idx in selected_indices:\n",
    "        checkpoint = checkpoints[idx]\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ANALYZING CHECKPOINT {idx}: {checkpoint['filename']}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        try:\n",
    "            model, metadata, device = load_model(checkpoint['path'])\n",
    "            \n",
    "            print(f\"Architecture: {metadata['architecture']}\")\n",
    "            print(f\"Training Episode: {metadata['episode']}\")\n",
    "            print(f\"Training Avg Reward: {metadata['avg_reward']}\")\n",
    "            print(f\"Training Epsilon: {metadata['epsilon']}\")\n",
    "            if metadata['total_steps'] != 'unknown':\n",
    "                print(f\"Total Training Steps: {metadata['total_steps']}\")\n",
    "            if metadata['run_id'] != 'unknown':\n",
    "                print(f\"Run ID: {metadata['run_id']}\")\n",
    "            print()\n",
    "            \n",
    "            video_path = None\n",
    "            should_save_video = False\n",
    "            \n",
    "            if SAVE_VIDEOS:\n",
    "                video_filename = checkpoint['filename'].replace('.pth', '_gameplay.mp4')\n",
    "                video_path = artifacts_dir / video_filename\n",
    "                \n",
    "                if checkpoint['filename'] in existing_videos and not FORCE_REGENERATE:\n",
    "                    print(f\"✓ Video already exists: {video_path}\")\n",
    "                    print(f\"  Skipping gameplay generation. Set FORCE_REGENERATE=True to regenerate.\")\n",
    "                    \n",
    "                    result = {\n",
    "                        'checkpoint': checkpoint['filename'],\n",
    "                        'architecture': metadata['architecture'],\n",
    "                        'training_episode': metadata['episode'],\n",
    "                        'training_avg_reward': metadata['avg_reward'],\n",
    "                        'training_epsilon': metadata['epsilon'],\n",
    "                        'video_size_mb': existing_videos[checkpoint['filename']]['size_mb'],\n",
    "                        'total_steps': metadata['total_steps'],\n",
    "                        'video_path': str(video_path),\n",
    "                        'video_status': 'existing'\n",
    "                    }\n",
    "                    results.append(result)\n",
    "                    continue\n",
    "                else:\n",
    "                    should_save_video = True\n",
    "                    if FORCE_REGENERATE and checkpoint['filename'] in existing_videos:\n",
    "                        print(f\"⚠ Regenerating existing video: {video_path}\")\n",
    "            \n",
    "            # Play game with VISUALIZATION_FRAME_SKIP parameter\n",
    "            final_reward, game_length = play_and_visualize_game(\n",
    "                model, device, checkpoint['filename'], metadata['architecture'],\n",
    "                visualization_frame_skip=VISUALIZATION_FRAME_SKIP,\n",
    "                save_video=should_save_video, video_path=video_path\n",
    "            )\n",
    "            \n",
    "            result = {\n",
    "                'checkpoint': checkpoint['filename'],\n",
    "                'architecture': metadata['architecture'],\n",
    "                'training_episode': metadata['episode'],\n",
    "                'training_avg_reward': metadata['avg_reward'],\n",
    "                'training_epsilon': metadata['epsilon'],\n",
    "                'game_reward': final_reward,\n",
    "                'game_length': game_length,\n",
    "                'total_steps': metadata['total_steps'],\n",
    "                'video_status': 'new'\n",
    "            }\n",
    "            if SAVE_VIDEOS:\n",
    "                result['video_path'] = str(video_path)\n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error with checkpoint {checkpoint['filename']}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Summary of results\n",
    "    if results:\n",
    "        print(f\"\\n{'='*100}\")\n",
    "        print(\"COMPREHENSIVE ANALYSIS SUMMARY - V2 RUN\")\n",
    "        print(f\"{'='*100}\")\n",
    "        \n",
    "        new_results = [r for r in results if r.get('video_status') == 'new']\n",
    "        existing_results = [r for r in results if r.get('video_status') == 'existing']\n",
    "        \n",
    "        if existing_results:\n",
    "            print(f\"\\nCheckpoints with existing videos ({len(existing_results)}):\")\n",
    "            print(f\"{'Checkpoint':<40} {'Architecture':<20} {'Train Ep':<10} {'Video Size (MB)':<15}\")\n",
    "            print(\"-\" * 100)\n",
    "            for result in existing_results:\n",
    "                print(f\"{result['checkpoint']:<40} {result['architecture']:<20} {str(result['training_episode']):<10} \"\n",
    "                      f\"{result['video_size_mb']:<15.2f}\")\n",
    "        \n",
    "        if new_results:\n",
    "            print(f\"\\nCheckpoints with new gameplay ({len(new_results)}):\")\n",
    "            print(f\"{'Checkpoint':<40} {'Architecture':<20} {'Train Ep':<10} {'Train Avg':<10} {'Game Reward':<12} {'Game Length':<12}\")\n",
    "            print(\"-\" * 100)\n",
    "            \n",
    "            for result in new_results:\n",
    "                print(f\"{result['checkpoint']:<40} {result['architecture']:<20} {str(result['training_episode']):<10} \"\n",
    "                      f\"{str(result['training_avg_reward']):<10} {result['game_reward']:<12.1f} {result['game_length']:<12}\")\n",
    "            \n",
    "            if new_results:\n",
    "                avg_game_reward = sum(r['game_reward'] for r in new_results) / len(new_results)\n",
    "                avg_game_length = sum(r['game_length'] for r in new_results) / len(new_results)\n",
    "                \n",
    "                print(\"-\" * 100)\n",
    "                print(f\"{'AVERAGES':<40} {'':<20} {'':<10} {'':<10} {avg_game_reward:<12.1f} {avg_game_length:<12.1f}\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        if SAVE_VIDEOS:\n",
    "            print(f\"Videos location: {artifacts_dir}\")\n",
    "            if new_results:\n",
    "                print(f\"  New videos generated: {len(new_results)}\")\n",
    "            if existing_results:\n",
    "                print(f\"  Existing videos reused: {len(existing_results)}\")\n",
    "            \n",
    "else:\n",
    "    print(\"No checkpoints available to analyze!\")\n",
    "    print(\"Make sure to run v2 training first with pong_dqn_cnn_v2.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
